{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explainability Demo\n",
        "\n",
        "This notebook demonstrates explainability methods for the depression detection model.\n",
        "\n",
        "## Methods\n",
        "\n",
        "1. **Saliency Maps**: Gradient-based feature importance\n",
        "2. **Integrated Gradients**: Path-integrated gradients\n",
        "3. **SHAP Values**: SHAP-based feature importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.insert(0, os.path.join('..', 'src'))\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from inference import DepressionDetector\n",
        "from explain.saliency import explain_audio, SaliencyExplainer\n",
        "from explain.shap_explain import explain_with_shap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load model\n",
        "model_path = '../models/best_model.pth'\n",
        "detector = DepressionDetector(model_path, balance_predictions=False)\n",
        "\n",
        "# Load test audio\n",
        "audio_path = '../tests/assets/test_audio.wav'  # Replace with your audio file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Saliency Maps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess audio\n",
        "segments = detector.preprocessor.process(audio_path)\n",
        "features = np.mean(segments, axis=0)\n",
        "features_tensor = torch.FloatTensor(features).unsqueeze(0).to(detector.device)\n",
        "\n",
        "# Generate saliency explanation\n",
        "explanation = explain_audio(\n",
        "    detector.model,\n",
        "    features_tensor,\n",
        "    method='saliency'\n",
        ")\n",
        "\n",
        "print(f\"Explanation type: {explanation['explanation_type']}\")\n",
        "print(f\"Top features: {explanation['top_features']}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
